{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(dataframe, inputs, targets):\n",
    "    data = SequentialDataSet(inputs, targets)\n",
    "    for i in range(0, self.dataframe.shape[0]-1):\n",
    "        row = dataframe.iloc[i]\n",
    "        data.newSequence()\n",
    "        ins = row.values\n",
    "        target =dataframe.iloc[i + 1].values[0]\n",
    "        data.appendLinked(ins, target)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45556348418\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pandas as pan\n",
    "import datahandler as dh\n",
    "import nethandler as nh\n",
    "from matplotlib import pyplot as pp\n",
    "import numpy as np\n",
    "#Input Data\n",
    "TRAINING_PERCENT = 0.50\n",
    "LAG_DAYS = 1\n",
    "startdate = '20000101'  # YYYYMMDD\n",
    "indices = [\"SQLDATE\", \"c_norm\", \"c_norm_lag1\"]\n",
    "\n",
    "#Neural Network\n",
    "INPUT = len(indices) * (LAG_DAYS+1)\n",
    "HIDDEN = 12\n",
    "OUTPUT = 1\n",
    "\n",
    "#Training\n",
    "ITERATIONS = 20\n",
    "LRATE = 0.4\n",
    "MOMENTUM = 0.6\n",
    "\n",
    "\n",
    "\n",
    "# filename_rates = '../clean_data/euro_exchange.csv'\n",
    "filename_rates = '../clean_data/log_log_exchange_rate_all_crisis.csv'\n",
    "data_euro_rate = pan.read_csv(filename_rates,usecols=[\"SQLDATE\",\"S_Log_Exchange\"])\n",
    "# data_euro_rate['Date'] =  pan.to_datetime(data_euro_rate['Date']).dt.strftime('%Y%m%d')\n",
    "data_euro_rate = data_euro_rate.set_index('SQLDATE')\n",
    "\n",
    "filename_greece = '../features/GDELT_I/greece.csv'\n",
    "data_greece = pan.read_csv(filename_greece,usecols=indices,index_col='SQLDATE')\n",
    "data_greece =  data_greece.loc[ data_euro_rate.iloc[0].name: data_euro_rate.iloc[-1].name]\n",
    "\n",
    "\n",
    "data_euro_rate['S_Log_Exchange'] =  np.exp(data_euro_rate['S_Log_Exchange'])\n",
    "\n",
    "data_euro_rate.index =  data_greece.index\n",
    "\n",
    "data =  pan.concat([data_euro_rate, data_greece],axis = 1)\n",
    "\n",
    "print data.iloc[1].values[0]\n",
    "# data_euro_rate.loc[mask]\n",
    "# print data_euro_rate.head\n",
    "# data.create_data(INPUT, OUTPUT)\n",
    "# train, test = data.get_datasets(TRAINING_PERCENT)\n",
    "# print \"Training:\", len(train), \"Testing:\", len(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-5f8a26ba3b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msp_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_ser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINING_PERCENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/duri/eth/ss2017/data_science/ds17-proj/prediction/nethandler.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, LRATE, MOMENTUM, ITERATIONS)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         trainer = BackpropTrainer(module=self.net, dataset=data, learningrate=LRATE,\n\u001b[0;32m---> 61\u001b[0;31m                                   momentum=MOMENTUM, lrdecay=0.99999, verbose=True)\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m# for i in xrange(0, self.initialization_periods):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#     self.net.activate(data.getSequence(i)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pybrain/supervised/trainers/backprop.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, dataset, learningrate, lrdecay, momentum, verbose, batchlearning, weightdecay)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \"\"\"\n\u001b[1;32m     34\u001b[0m         \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchlearning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchlearning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pybrain/supervised/trainers/trainer.pyc\u001b[0m in \u001b[0;36msetData\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m\"\"\"Associate the given dataset with the trainer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    916\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "\n",
    "sp_net = nh.NetHandler(INPUT, HIDDEN, OUTPUT, data)\n",
    "train_errors, val_errors = sp_net.train(data, LRATE, MOMENTUM, ITERATIONS)\n",
    "\n",
    "out_ser = sp_net.get_output(test, TRAINING_PERCENT)\n",
    "print \"Net Topology: %d-%d-%d\" % (INPUT, HIDDEN, OUTPUT)\n",
    "print sp_net.change_tomorrow()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "misses = 0\n",
    "for index, row in out_ser.iteritems():\n",
    "    try:\n",
    "        actual = data.dataframe.ix[:, 0][index]\n",
    "        total += 1\n",
    "        if row > 0 and actual > 0:\n",
    "            correct += 1\n",
    "        elif row < 0 and actual < 0:\n",
    "            correct += 1\n",
    "    except KeyError:\n",
    "        misses += 1\n",
    "print \"%.3f%% Directional Accuracy\" % (float(correct) / float(total) * 100)\n",
    "print \"(%d misses)\" % misses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.figure(0)\n",
    "data.dataframe.ix[:, 0].plot(style='bo-', alpha=0.8)\n",
    "data.dataframe.ix[:, (LAG_DAYS+1) * 1].plot(style='g-', alpha=0.5)\n",
    "data.dataframe.ix[:, (LAG_DAYS+1) * 2].plot(style='y-', alpha=0.5)\n",
    "data.dataframe.ix[:, (LAG_DAYS+1) * 3].plot(style='m-', alpha=0.5)\n",
    "data.dataframe.ix[:, (LAG_DAYS+1) * 4].plot(style='c-', alpha=0.5)\n",
    "data.dataframe.ix[:, (LAG_DAYS+1) * 5].plot(style='-', color='0.75', alpha=0.5)\n",
    "out_ser.plot(style='ro-')\n",
    "pp.axhline(0, color='black')\n",
    "\n",
    "pp.figure(1)\n",
    "pp.plot(train_errors)\n",
    "pp.plot(val_errors)\n",
    "pp.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
